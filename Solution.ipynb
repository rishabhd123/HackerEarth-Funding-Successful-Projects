{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "project_id = test['project_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unix_cols = ['deadline','state_changed_at','launched_at','created_at']\n",
    "for x in unix_cols:\n",
    "    train[x] = train[x].apply(lambda k: datetime.datetime.fromtimestamp(int(k)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    test[x] = test[x].apply(lambda k: datetime.datetime.fromtimestamp(int(k)).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['name','desc']\n",
    "len_feats = ['name_len','desc_len']\n",
    "count_feats = ['name_count','desc_count']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    train[len_feats[i]] = train[cols_to_use[i]].apply(str).apply(len)\n",
    "    test[len_feats[i]] = test[cols_to_use[i]].apply(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['name_count'] = train['name'].str.split().str.len()\n",
    "train['desc_count'] = train['desc'].str.split().str.len()\n",
    "\n",
    "test['name_count'] = test['name'].str.split().str.len()\n",
    "test['desc_count'] = test['desc'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['keywords_len'] = train['keywords'].str.len()\n",
    "train['keywords_count'] = train['keywords'].str.split('-').str.len()\n",
    "\n",
    "test['keywords_len'] = test['keywords'].str.len()\n",
    "test['keywords_count'] = test['keywords'].str.split('-').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unix_cols = ['deadline','state_changed_at','launched_at','created_at']\n",
    "\n",
    "for x in unix_cols:\n",
    "    train[x] = train[x].apply(lambda k: datetime.datetime.strptime(k, '%Y-%m-%d %H:%M:%S'))\n",
    "    test[x] = test[x].apply(lambda k: datetime.datetime.strptime(k, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = (train['launched_at']-train['created_at']).astype('timedelta64[s]')\n",
    "time3 = (train['deadline']-train['launched_at']).astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['time1'] = np.log(time1)\n",
    "train['time3'] = np.log(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time5 = (test['launched_at']-test['created_at']).astype('timedelta64[s]')\n",
    "time6 = (test['deadline']-test['launched_at']).astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['time1'] = np.log(time5)\n",
    "test['time3'] = np.log(time6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = ['disable_communication','country']\n",
    "\n",
    "for x in feat:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[x].values) + list(test[x].values))\n",
    "    train[x] = le.transform(list(train[x]))\n",
    "    test[x] = le.transform(list(test[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['goal'] = np.log1p(train['goal'])\n",
    "test['goal'] = np.log1p(test['goal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kickdesc = pd.Series(train['desc'].tolist() + test['desc'].tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def desc_clean(word):\n",
    "    p1 = re.sub(pattern='(\\W+)|(\\d+)|(\\s+)',repl=' ',string=word)\n",
    "    p1 = p1.lower()\n",
    "    return p1\n",
    "\n",
    "kickdesc = kickdesc.map(desc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "kickdesc = [[x for x in x.split() if x not in stop] for x in kickdesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "kickdesc = [[stemmer.stem(x) for x in x] for x in kickdesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kickdesc = [[x for x in x if len(x) > 2] for x in kickdesc]\n",
    "kickdesc = [' '.join(x) for x in kickdesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldesc = cv.fit_transform(kickdesc).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine = pd.DataFrame(alldesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine.rename(columns= lambda x: 'variable_'+ str(x), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = combine[:train.shape[0]]\n",
    "test_text = combine[train.shape[0]:]\n",
    "\n",
    "test_text.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['name_len','desc_len','keywords_len','name_count','desc_count','keywords_count','time1','time3','goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train['final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.loc[:,cols_to_use]\n",
    "test = test.loc[:,cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([train, train_text],axis=1)\n",
    "X_test = pd.concat([test, test_text],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(X_train, target, test_size=0.40, random_state=2017);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clabuser/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "preds = X_train.columns\n",
    "dtrain = xgb.DMatrix(train_X, train_Y, feature_names=preds)\n",
    "dval = xgb.DMatrix(val_X, val_Y, feature_names=preds)                     \n",
    "dtrain_all = xgb.DMatrix(X_train, target, feature_names=preds)\n",
    "dtest = xgb.DMatrix(data=X_test, feature_names=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'error',\n",
    "    'eta':0.02,\n",
    "    'max_depth':9,\n",
    "    'subsample':0.7,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':2,\n",
    "    'seed': 2017\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTraining-error:0.305686\tValidation-error:0.317835\n",
      "Multiple eval metrics have been passed: 'Validation-error' will be used for early stopping.\n",
      "\n",
      "Will train until Validation-error hasn't improved in 50 rounds.\n",
      "[25]\tTraining-error:0.292415\tValidation-error:0.308772\n",
      "[50]\tTraining-error:0.286111\tValidation-error:0.305974\n",
      "[75]\tTraining-error:0.281009\tValidation-error:0.303431\n",
      "[100]\tTraining-error:0.277541\tValidation-error:0.301859\n",
      "[125]\tTraining-error:0.273225\tValidation-error:0.299847\n",
      "[150]\tTraining-error:0.270358\tValidation-error:0.298553\n",
      "[175]\tTraining-error:0.267876\tValidation-error:0.297489\n",
      "[200]\tTraining-error:0.265441\tValidation-error:0.296934\n",
      "[225]\tTraining-error:0.262466\tValidation-error:0.295663\n",
      "[250]\tTraining-error:0.260478\tValidation-error:0.295593\n",
      "[275]\tTraining-error:0.257842\tValidation-error:0.294761\n",
      "[300]\tTraining-error:0.255514\tValidation-error:0.293882\n",
      "[325]\tTraining-error:0.253387\tValidation-error:0.293674\n",
      "[350]\tTraining-error:0.251214\tValidation-error:0.292449\n",
      "[375]\tTraining-error:0.249241\tValidation-error:0.292426\n",
      "[400]\tTraining-error:0.247823\tValidation-error:0.292056\n",
      "[425]\tTraining-error:0.245927\tValidation-error:0.292218\n",
      "[450]\tTraining-error:0.243969\tValidation-error:0.292033\n",
      "[475]\tTraining-error:0.242073\tValidation-error:0.291524\n",
      "[500]\tTraining-error:0.24064\tValidation-error:0.29164\n",
      "[525]\tTraining-error:0.23859\tValidation-error:0.2909\n",
      "[550]\tTraining-error:0.236817\tValidation-error:0.290484\n",
      "[575]\tTraining-error:0.235446\tValidation-error:0.289998\n",
      "[600]\tTraining-error:0.233272\tValidation-error:0.290044\n",
      "[625]\tTraining-error:0.231839\tValidation-error:0.28979\n",
      "[650]\tTraining-error:0.230082\tValidation-error:0.289998\n",
      "[675]\tTraining-error:0.228663\tValidation-error:0.289929\n",
      "Stopping. Best iteration:\n",
      "[635]\tTraining-error:0.231253\tValidation-error:0.289328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist =[(dtrain,'Training'), (dval, 'Validation')]\n",
    "num_rounds = 2500\n",
    "model = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=25 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain_all, num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = bst_train.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['project_id'] = project_id\n",
    "sub['final_status'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub['final_status'] = [1 if x > 0.5 else 0 for x in sub['final_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"subm.csv\",index=False) #0.70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
