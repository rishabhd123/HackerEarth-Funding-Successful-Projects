{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "project_id = test['project_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unix_cols = ['deadline','state_changed_at','launched_at','created_at']\n",
    "for x in unix_cols:\n",
    "    train[x] = train[x].apply(lambda k: datetime.datetime.fromtimestamp(int(k)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    test[x] = test[x].apply(lambda k: datetime.datetime.fromtimestamp(int(k)).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['name','desc']\n",
    "len_feats = ['name_len','desc_len']\n",
    "count_feats = ['name_count','desc_count']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    train[len_feats[i]] = train[cols_to_use[i]].apply(str).apply(len)\n",
    "    test[len_feats[i]] = test[cols_to_use[i]].apply(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['name_count'] = train['name'].str.split().str.len()\n",
    "train['desc_count'] = train['desc'].str.split().str.len()\n",
    "\n",
    "test['name_count'] = test['name'].str.split().str.len()\n",
    "test['desc_count'] = test['desc'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['keywords_len'] = train['keywords'].str.len()\n",
    "train['keywords_count'] = train['keywords'].str.split('-').str.len()\n",
    "\n",
    "test['keywords_len'] = test['keywords'].str.len()\n",
    "test['keywords_count'] = test['keywords'].str.split('-').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unix_cols = ['deadline','state_changed_at','launched_at','created_at']\n",
    "\n",
    "for x in unix_cols:\n",
    "    train[x] = train[x].apply(lambda k: datetime.datetime.strptime(k, '%Y-%m-%d %H:%M:%S'))\n",
    "    test[x] = test[x].apply(lambda k: datetime.datetime.strptime(k, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = (train['launched_at']-train['created_at']).astype('timedelta64[s]')\n",
    "time3 = (train['deadline']-train['launched_at']).astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['time1'] = np.log(time1)\n",
    "train['time3'] = np.log(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time5 = (test['launched_at']-test['created_at']).astype('timedelta64[s]')\n",
    "time6 = (test['deadline']-test['launched_at']).astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['time1'] = np.log(time5)\n",
    "test['time3'] = np.log(time6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = ['disable_communication','country']\n",
    "\n",
    "for x in feat:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[x].values) + list(test[x].values))\n",
    "    train[x] = le.transform(list(train[x]))\n",
    "    test[x] = le.transform(list(test[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['goal'] = np.log1p(train['goal'])\n",
    "test['goal'] = np.log1p(test['goal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kickdesc = pd.Series(train['desc'].tolist() + test['desc'].tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def desc_clean(word):\n",
    "    p1 = re.sub(pattern='(\\W+)|(\\d+)|(\\s+)',repl=' ',string=word)\n",
    "    p1 = p1.lower()\n",
    "    return p1\n",
    "\n",
    "kickdesc = kickdesc.map(desc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "kickdesc = [[x for x in x.split() if x not in stop] for x in kickdesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "kickdesc = [[stemmer.stem(x) for x in x] for x in kickdesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kickdesc = [[x for x in x if len(x) > 2] for x in kickdesc]\n",
    "kickdesc = [' '.join(x) for x in kickdesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldesc = cv.fit_transform(kickdesc).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine = pd.DataFrame(alldesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine.rename(columns= lambda x: 'variable_'+ str(x), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = combine[:train.shape[0]]\n",
    "test_text = combine[train.shape[0]:]\n",
    "\n",
    "test_text.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['name_len','desc_len','keywords_len','name_count','desc_count','keywords_count','time1','time3','goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train['final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.loc[:,cols_to_use]\n",
    "test = test.loc[:,cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([train, train_text],axis=1)\n",
    "X_test = pd.concat([test, test_text],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(X_train, target, test_size=0.40, random_state=2017);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clabuser/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "preds = X_train.columns\n",
    "dtrain = xgb.DMatrix(train_X, train_Y, feature_names=preds)\n",
    "dval = xgb.DMatrix(val_X, val_Y, feature_names=preds)                     \n",
    "dtrain_all = xgb.DMatrix(X_train, target, feature_names=preds)\n",
    "dtest = xgb.DMatrix(data=X_test, feature_names=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'error',\n",
    "    'eta':0.025,\n",
    "    'max_depth':7,\n",
    "    'subsample':0.7,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':5,\n",
    "    'seed': 2017    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTraining-error:0.311112\tValidation-error:0.318598\n",
      "Multiple eval metrics have been passed: 'Validation-error' will be used for early stopping.\n",
      "\n",
      "Will train until Validation-error hasn't improved in 50 rounds.\n",
      "[25]\tTraining-error:0.30359\tValidation-error:0.31076\n",
      "[50]\tTraining-error:0.29818\tValidation-error:0.308263\n",
      "[75]\tTraining-error:0.293386\tValidation-error:0.304841\n",
      "[100]\tTraining-error:0.290504\tValidation-error:0.302321\n",
      "[125]\tTraining-error:0.287359\tValidation-error:0.300587\n",
      "[150]\tTraining-error:0.285355\tValidation-error:0.299293\n",
      "[175]\tTraining-error:0.283244\tValidation-error:0.298229\n",
      "[200]\tTraining-error:0.280993\tValidation-error:0.296634\n",
      "[225]\tTraining-error:0.278712\tValidation-error:0.295824\n",
      "[250]\tTraining-error:0.277217\tValidation-error:0.29564\n",
      "[275]\tTraining-error:0.276076\tValidation-error:0.294992\n",
      "[300]\tTraining-error:0.274304\tValidation-error:0.294414\n",
      "[325]\tTraining-error:0.272716\tValidation-error:0.293929\n",
      "[350]\tTraining-error:0.270697\tValidation-error:0.293189\n",
      "[375]\tTraining-error:0.269911\tValidation-error:0.292726\n",
      "[400]\tTraining-error:0.268446\tValidation-error:0.292056\n",
      "[425]\tTraining-error:0.266998\tValidation-error:0.291709\n",
      "[450]\tTraining-error:0.265703\tValidation-error:0.291524\n",
      "[475]\tTraining-error:0.2641\tValidation-error:0.290669\n",
      "[500]\tTraining-error:0.262589\tValidation-error:0.290437\n",
      "[525]\tTraining-error:0.261649\tValidation-error:0.290646\n",
      "[550]\tTraining-error:0.260046\tValidation-error:0.290068\n",
      "[575]\tTraining-error:0.259044\tValidation-error:0.289559\n",
      "[600]\tTraining-error:0.257996\tValidation-error:0.289721\n",
      "[625]\tTraining-error:0.256593\tValidation-error:0.289698\n",
      "[650]\tTraining-error:0.255684\tValidation-error:0.28979\n",
      "[675]\tTraining-error:0.254605\tValidation-error:0.289536\n",
      "Stopping. Best iteration:\n",
      "[627]\tTraining-error:0.256439\tValidation-error:0.289328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist =[(dtrain,'Training'), (dval, 'Validation')]\n",
    "num_rounds = 2500\n",
    "model = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain_all, num_boost_round=int(681/0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['project_id'] = project_id\n",
    "sub['final_status'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub['final_status'] = [1 if x > 0.5 else 0 for x in sub['final_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"subm.csv\",index=False) #0.70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
